{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1025) must match the size of tensor b (1024) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-bcd3c969f82c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# output[0] is the weight of last layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pytorch_transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, position_ids, token_type_ids, labels, past, head_mask)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         transformer_outputs = self.transformer(input_ids, position_ids=position_ids, token_type_ids=token_type_ids,\n\u001b[1;32m--> 606\u001b[1;33m                                                past=past, head_mask=head_mask)\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pytorch_transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, position_ids, token_type_ids, past, head_mask)\u001b[0m\n\u001b[0;32m    521\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0mpresents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresents\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpresent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pytorch_transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, layer_past, head_mask)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0moutput_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_attn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pytorch_transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, layer_past, head_mask)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mpresent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# transpose to have same shapes for stacking\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mattn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\pytorch_transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[1;34m(self, q, k, v, head_mask)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mnd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1e4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1025) must match the size of tensor b (1024) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set the model in evaluation mode to desactivate the DropOut modules\n",
    "# This is IMPORTANT to have reproductible results during evaluation!\n",
    "model.eval()\n",
    "\n",
    "# Read the story and split word\n",
    "file1 = open(\"MTS_allSegments.txt\",\"r\") \n",
    "story = file1.readlines()\n",
    "story_list = story[0].lower().split()\n",
    "\n",
    "# Initialize the list to store weights\n",
    "next_weight = []\n",
    "\n",
    "# the loop is from 5th word to last word so the first prediction has some context\n",
    "for iWord in range(5,len(story_list)):\n",
    "    next_word = story_list[iWord]\n",
    "    context_word = story_list[0:(iWord-1)]\n",
    "    \n",
    "    seperator = ' '\n",
    "    text = seperator.join(context_word)\n",
    "    \n",
    "    # Encode a text inputs\n",
    "    indexed_tokens = tokenizer.encode(text)\n",
    "    \n",
    "    # Convert indexed tokens in a PyTorch tensor\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    \n",
    "    # If you have a GPU, put everything on cuda\n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    model.to('cuda')\n",
    "    \n",
    "    # Predict all tokens\n",
    "    # output[0] is the weight of last layer\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    # get the weight for the predicted last word\n",
    "    next_weight.append(predictions[0, -1, tokenizer.encode(next_word)[0]].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'briefest'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4506, 395]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(next_word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'est'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(395)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = predictions[0, -1, tokenizer.encode(next_word)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-123.83051300048828,\n",
       " -98.8583984375,\n",
       " -116.5068359375,\n",
       " -92.15135192871094,\n",
       " -88.73371887207031,\n",
       " -100.98986053466797,\n",
       " -81.22249603271484,\n",
       " -98.21540832519531,\n",
       " -127.51956939697266,\n",
       " -131.44882202148438,\n",
       " -124.65025329589844,\n",
       " -116.20816802978516,\n",
       " -61.86349868774414,\n",
       " -93.25726318359375,\n",
       " -91.71890258789062,\n",
       " -94.01568603515625,\n",
       " -111.51834869384766,\n",
       " -77.42327880859375,\n",
       " -95.18460845947266,\n",
       " -93.32532501220703,\n",
       " -90.14218139648438,\n",
       " -108.11395263671875,\n",
       " -137.4080047607422,\n",
       " -130.92416381835938,\n",
       " -114.71525573730469,\n",
       " -98.24365234375,\n",
       " -108.7219467163086,\n",
       " -91.64990234375,\n",
       " -106.17044830322266,\n",
       " -133.21197509765625,\n",
       " -100.90234375,\n",
       " -98.4674072265625,\n",
       " -90.92073059082031,\n",
       " -92.66871643066406,\n",
       " -108.53067016601562,\n",
       " -81.91979217529297,\n",
       " -90.33348846435547,\n",
       " -98.84242248535156,\n",
       " -110.22178649902344,\n",
       " -110.99372863769531,\n",
       " -120.15365600585938,\n",
       " -106.49329376220703,\n",
       " -87.09664916992188,\n",
       " -109.5851821899414,\n",
       " -97.060791015625,\n",
       " -102.31961822509766,\n",
       " -83.16214752197266,\n",
       " -109.267822265625,\n",
       " -132.99325561523438,\n",
       " -110.30488586425781,\n",
       " -112.77459716796875,\n",
       " -112.14885711669922,\n",
       " -126.46577453613281,\n",
       " -132.9002227783203,\n",
       " -130.50965881347656,\n",
       " -141.0135955810547,\n",
       " -146.5820770263672,\n",
       " -119.5404052734375,\n",
       " -135.78150939941406,\n",
       " -131.85235595703125,\n",
       " -118.96102142333984,\n",
       " -120.72750854492188,\n",
       " -48.39776611328125,\n",
       " -144.00157165527344,\n",
       " -128.79168701171875,\n",
       " -85.27513885498047,\n",
       " -86.56614685058594,\n",
       " -105.08175659179688,\n",
       " -118.74435424804688,\n",
       " -107.9527587890625,\n",
       " -125.15862274169922,\n",
       " -107.9908447265625,\n",
       " -100.38248443603516,\n",
       " -98.09690856933594,\n",
       " -117.19082641601562,\n",
       " -121.26808166503906,\n",
       " -136.8978729248047,\n",
       " -79.9295883178711,\n",
       " -92.1541976928711,\n",
       " -116.03331756591797,\n",
       " -114.18357849121094,\n",
       " -109.10920715332031,\n",
       " -101.11012268066406,\n",
       " -100.67105102539062,\n",
       " -80.27526092529297,\n",
       " -100.35416412353516,\n",
       " -122.09967803955078,\n",
       " -104.49085998535156,\n",
       " -131.76065063476562,\n",
       " -135.8600311279297,\n",
       " -131.40512084960938,\n",
       " -124.31460571289062,\n",
       " -101.6080551147461,\n",
       " -100.64311981201172,\n",
       " -111.59611511230469,\n",
       " -122.86695861816406,\n",
       " -88.53471374511719,\n",
       " -123.23486328125,\n",
       " -105.307373046875,\n",
       " -53.710716247558594,\n",
       " -78.99198150634766,\n",
       " -114.87702941894531,\n",
       " -132.83311462402344,\n",
       " -124.0642318725586,\n",
       " -134.0825653076172,\n",
       " -127.94475555419922,\n",
       " -108.59159851074219,\n",
       " -133.49993896484375,\n",
       " -105.35713195800781,\n",
       " -130.30941772460938,\n",
       " -127.04757690429688,\n",
       " -123.35733032226562,\n",
       " -115.69058990478516,\n",
       " -106.81171417236328,\n",
       " -121.94351959228516,\n",
       " -132.9979705810547,\n",
       " -112.78825378417969,\n",
       " -95.90345001220703,\n",
       " -129.92361450195312,\n",
       " -131.0790252685547,\n",
       " -132.00584411621094,\n",
       " -133.52783203125,\n",
       " -101.68196868896484,\n",
       " -109.67383575439453,\n",
       " -123.78150939941406,\n",
       " -110.08139038085938,\n",
       " -124.2613525390625,\n",
       " -120.59046173095703,\n",
       " -140.4891815185547,\n",
       " -103.61647033691406,\n",
       " -131.99246215820312,\n",
       " -79.70913696289062,\n",
       " -126.01165008544922,\n",
       " -90.49623107910156,\n",
       " -112.64598846435547,\n",
       " -108.57511901855469,\n",
       " -114.4231948852539,\n",
       " -127.0395278930664,\n",
       " -118.31019592285156,\n",
       " -105.81623840332031,\n",
       " -108.56413269042969,\n",
       " -84.65874481201172,\n",
       " -107.95774841308594,\n",
       " -105.34391021728516,\n",
       " -123.02931213378906,\n",
       " -138.9199676513672,\n",
       " -137.08148193359375,\n",
       " -110.43623352050781,\n",
       " -119.78627014160156,\n",
       " -154.35791015625,\n",
       " -111.48087310791016,\n",
       " -101.93470001220703,\n",
       " -115.27006530761719,\n",
       " -127.19763946533203,\n",
       " -135.29437255859375,\n",
       " -148.11317443847656,\n",
       " -103.51123809814453,\n",
       " -124.02711486816406,\n",
       " -118.98529815673828,\n",
       " -85.15808868408203,\n",
       " -112.4283447265625,\n",
       " -87.79490661621094,\n",
       " -92.10456848144531,\n",
       " -130.36488342285156,\n",
       " -123.73600769042969,\n",
       " -130.49473571777344,\n",
       " -132.3500518798828,\n",
       " -110.12600708007812,\n",
       " -121.22557067871094,\n",
       " -76.97230529785156,\n",
       " -114.83495330810547,\n",
       " -68.63578033447266,\n",
       " -117.31790924072266,\n",
       " -124.01953125,\n",
       " -103.55216217041016,\n",
       " -122.67894744873047,\n",
       " -122.79007720947266,\n",
       " -119.45231628417969,\n",
       " -96.63910675048828,\n",
       " -148.29856872558594,\n",
       " -138.9605255126953,\n",
       " -108.60523223876953,\n",
       " -113.54780578613281,\n",
       " -118.63536834716797,\n",
       " -132.9427947998047,\n",
       " -137.25828552246094,\n",
       " -145.84669494628906,\n",
       " -120.68528747558594,\n",
       " -139.66160583496094,\n",
       " -108.55622863769531,\n",
       " -127.50672912597656,\n",
       " -101.57972717285156,\n",
       " -120.00576782226562,\n",
       " -130.43020629882812,\n",
       " -140.6009979248047,\n",
       " -123.08522033691406,\n",
       " -124.43084716796875,\n",
       " -139.30563354492188,\n",
       " -62.59461975097656,\n",
       " -109.9775619506836,\n",
       " -116.75432586669922,\n",
       " -136.18682861328125,\n",
       " -100.34442138671875,\n",
       " -106.20390319824219,\n",
       " -131.45852661132812,\n",
       " -102.42194366455078,\n",
       " -120.03628540039062,\n",
       " -130.5707550048828,\n",
       " -111.68811798095703,\n",
       " -134.6305694580078,\n",
       " -102.83876037597656,\n",
       " -132.6776123046875,\n",
       " -145.46360778808594,\n",
       " -137.4350128173828,\n",
       " -106.72526550292969,\n",
       " -136.7020263671875,\n",
       " -128.13211059570312,\n",
       " -143.72268676757812,\n",
       " -135.22117614746094,\n",
       " -125.57808685302734,\n",
       " -89.58472442626953,\n",
       " -111.33873748779297,\n",
       " -128.5456085205078,\n",
       " -112.35305786132812,\n",
       " -128.47647094726562,\n",
       " -89.89746856689453,\n",
       " -111.02175903320312,\n",
       " -103.91512298583984,\n",
       " -116.18252563476562,\n",
       " -99.40058135986328,\n",
       " -97.21149444580078,\n",
       " -109.76158905029297,\n",
       " -117.0213851928711,\n",
       " -98.60520935058594,\n",
       " -104.87662506103516,\n",
       " -101.14289093017578,\n",
       " -98.70142364501953,\n",
       " -112.56314849853516,\n",
       " -111.51599884033203,\n",
       " -105.5351791381836,\n",
       " -125.41810607910156,\n",
       " -112.27381134033203,\n",
       " -97.92366027832031,\n",
       " -107.62235260009766,\n",
       " -109.13096618652344,\n",
       " -136.5124053955078,\n",
       " -136.8229217529297,\n",
       " -124.97686767578125,\n",
       " -148.38658142089844,\n",
       " -118.47187805175781,\n",
       " -115.67526245117188,\n",
       " -100.7071304321289,\n",
       " -117.63133239746094,\n",
       " -131.7854766845703,\n",
       " -97.98262786865234,\n",
       " -133.6356201171875,\n",
       " -138.16201782226562,\n",
       " -106.22344970703125,\n",
       " -125.12049102783203,\n",
       " -119.18643951416016,\n",
       " -116.14481353759766,\n",
       " -129.72238159179688,\n",
       " -138.46249389648438,\n",
       " -118.55504608154297,\n",
       " -139.1631317138672,\n",
       " -135.54287719726562,\n",
       " -109.04460906982422,\n",
       " -106.6839828491211,\n",
       " -133.57412719726562,\n",
       " -120.14083862304688,\n",
       " -96.00162506103516,\n",
       " -114.94246673583984,\n",
       " -93.398681640625,\n",
       " -98.27561950683594,\n",
       " -106.12846374511719,\n",
       " -120.70982360839844,\n",
       " -95.33171844482422,\n",
       " -82.91524505615234,\n",
       " -118.55513763427734,\n",
       " -112.16326141357422,\n",
       " -113.10652160644531,\n",
       " -107.7119369506836,\n",
       " -122.90898895263672,\n",
       " -134.9378204345703,\n",
       " -148.0944366455078,\n",
       " -141.88690185546875,\n",
       " -119.7576904296875,\n",
       " -148.8831024169922,\n",
       " -103.89789581298828,\n",
       " -134.65829467773438,\n",
       " -127.05683898925781,\n",
       " -128.80836486816406,\n",
       " -137.63345336914062,\n",
       " -77.74151611328125,\n",
       " -148.29541015625,\n",
       " -123.02728271484375,\n",
       " -137.1104736328125,\n",
       " -143.09036254882812,\n",
       " -116.56395721435547,\n",
       " -98.24513244628906,\n",
       " -102.05345916748047,\n",
       " -113.4354248046875,\n",
       " -106.58206939697266,\n",
       " -137.88372802734375,\n",
       " -88.90817260742188,\n",
       " -94.75115966796875,\n",
       " -103.6040267944336,\n",
       " -125.30280303955078,\n",
       " -105.44331359863281,\n",
       " -122.29319763183594,\n",
       " -125.53617858886719,\n",
       " -109.17339324951172,\n",
       " -104.81669616699219,\n",
       " -99.94256591796875,\n",
       " -124.4037094116211,\n",
       " -137.20555114746094,\n",
       " -140.6499786376953,\n",
       " -124.10647583007812,\n",
       " -118.69821166992188,\n",
       " -118.0135498046875,\n",
       " -113.00545501708984,\n",
       " -107.61880493164062,\n",
       " -133.5437774658203,\n",
       " -106.0794677734375,\n",
       " -68.56491088867188,\n",
       " -112.19218444824219,\n",
       " -132.7978057861328,\n",
       " -118.86649322509766,\n",
       " -95.86609649658203,\n",
       " -126.6642074584961,\n",
       " -108.49434661865234,\n",
       " -125.12415313720703,\n",
       " -147.89620971679688,\n",
       " -142.56381225585938,\n",
       " -115.62869262695312,\n",
       " -102.31238555908203,\n",
       " -110.41215515136719,\n",
       " -93.12825775146484,\n",
       " -95.4632797241211,\n",
       " -109.49280548095703,\n",
       " -128.4236297607422,\n",
       " -113.91808319091797,\n",
       " -120.03038024902344,\n",
       " -140.53860473632812,\n",
       " -117.31143951416016,\n",
       " -120.54182434082031,\n",
       " -106.43573760986328,\n",
       " -120.94119262695312,\n",
       " -141.88388061523438,\n",
       " -139.7816619873047,\n",
       " -121.36761474609375,\n",
       " -126.82469177246094,\n",
       " -133.0775146484375,\n",
       " -119.10322570800781,\n",
       " -110.01162719726562,\n",
       " -138.66461181640625,\n",
       " -113.7557601928711,\n",
       " -132.02012634277344,\n",
       " -153.2547149658203,\n",
       " -140.39935302734375,\n",
       " -103.13277435302734,\n",
       " -113.9141845703125,\n",
       " -131.1518096923828,\n",
       " -128.6331787109375,\n",
       " -130.4369354248047,\n",
       " -137.9484100341797,\n",
       " -131.44757080078125,\n",
       " -106.74658966064453,\n",
       " -121.82318878173828,\n",
       " -118.12480163574219,\n",
       " -125.0672607421875,\n",
       " -118.71817016601562,\n",
       " -126.62382507324219,\n",
       " -125.47430419921875,\n",
       " -119.83507537841797,\n",
       " -141.26292419433594,\n",
       " -103.30551147460938,\n",
       " -101.61479949951172,\n",
       " -110.0835952758789,\n",
       " -122.18314361572266,\n",
       " -110.94854736328125,\n",
       " -134.77059936523438,\n",
       " -131.5995330810547,\n",
       " -120.98685455322266,\n",
       " -143.14144897460938,\n",
       " -139.4385223388672,\n",
       " -108.4489974975586,\n",
       " -114.99673461914062,\n",
       " -125.35850524902344,\n",
       " -119.43932342529297,\n",
       " -137.9651336669922,\n",
       " -115.93215942382812,\n",
       " -118.28467559814453,\n",
       " -116.33768463134766,\n",
       " -128.01626586914062,\n",
       " -125.46868896484375,\n",
       " -110.67731475830078,\n",
       " -114.57752227783203,\n",
       " -109.71040344238281,\n",
       " -119.17606353759766,\n",
       " -126.95475006103516,\n",
       " -78.62703704833984,\n",
       " -102.7082748413086,\n",
       " -139.48692321777344,\n",
       " -149.80560302734375,\n",
       " -98.2252426147461,\n",
       " -109.5514907836914,\n",
       " -112.20594787597656,\n",
       " -109.6505355834961,\n",
       " -102.51338195800781,\n",
       " -110.97872924804688,\n",
       " -105.270263671875,\n",
       " -116.9829330444336,\n",
       " -143.02322387695312,\n",
       " -131.1260986328125,\n",
       " -116.30889892578125,\n",
       " -128.5594024658203,\n",
       " -105.8049087524414,\n",
       " -111.45696258544922,\n",
       " -117.82275390625,\n",
       " -141.4967803955078,\n",
       " -123.74334716796875,\n",
       " -133.37889099121094,\n",
       " -153.2627410888672,\n",
       " -114.36103820800781,\n",
       " -108.20629119873047,\n",
       " -109.59176635742188,\n",
       " -119.18382263183594,\n",
       " -121.65018463134766,\n",
       " -128.54388427734375,\n",
       " -111.43989562988281,\n",
       " -136.65110778808594,\n",
       " -138.7471466064453,\n",
       " -136.2188720703125,\n",
       " -71.42601776123047,\n",
       " -128.56173706054688,\n",
       " -117.35323333740234,\n",
       " -127.70236206054688,\n",
       " -152.94139099121094,\n",
       " -122.75812530517578,\n",
       " -110.4933090209961,\n",
       " -89.54168701171875,\n",
       " -111.02790069580078,\n",
       " -129.19639587402344,\n",
       " -142.03836059570312,\n",
       " -125.20055389404297,\n",
       " -107.31473541259766,\n",
       " -110.95337677001953,\n",
       " -126.0514144897461,\n",
       " -106.2867660522461,\n",
       " -134.7777099609375,\n",
       " -119.9874496459961,\n",
       " -138.17385864257812,\n",
       " -136.27877807617188,\n",
       " -117.6956787109375,\n",
       " -121.89015197753906,\n",
       " -125.27411651611328,\n",
       " -116.33185577392578,\n",
       " -131.64356994628906,\n",
       " -140.86947631835938,\n",
       " -138.88427734375,\n",
       " -132.02670288085938,\n",
       " -127.566650390625,\n",
       " -112.09481811523438,\n",
       " -117.36261749267578,\n",
       " -130.53041076660156,\n",
       " -140.43482971191406,\n",
       " -147.5485382080078,\n",
       " -106.55685424804688,\n",
       " -127.04132843017578,\n",
       " -135.77516174316406,\n",
       " -146.41151428222656,\n",
       " -139.34042358398438,\n",
       " -122.40403747558594,\n",
       " -130.50750732421875,\n",
       " -137.28045654296875,\n",
       " -110.84175872802734,\n",
       " -111.2033462524414,\n",
       " -131.6465301513672,\n",
       " -114.08434295654297,\n",
       " -119.91603088378906,\n",
       " -129.816162109375,\n",
       " -145.79473876953125,\n",
       " -116.29434204101562,\n",
       " -119.61162567138672,\n",
       " -111.6151123046875,\n",
       " -108.85623168945312,\n",
       " -126.9749984741211,\n",
       " -114.87479400634766,\n",
       " -120.06586456298828,\n",
       " -124.17439270019531,\n",
       " -117.69865417480469,\n",
       " -97.05525970458984,\n",
       " -122.88428497314453,\n",
       " -137.42733764648438,\n",
       " -102.39479064941406,\n",
       " -115.4189682006836,\n",
       " -132.6770782470703,\n",
       " -126.22139739990234,\n",
       " -135.43661499023438,\n",
       " -139.6077880859375,\n",
       " -107.3171615600586,\n",
       " -115.51789855957031,\n",
       " -122.41845703125,\n",
       " -130.22938537597656,\n",
       " -100.25762939453125,\n",
       " -108.76546478271484,\n",
       " -133.0516815185547,\n",
       " -143.43960571289062,\n",
       " -121.51802062988281,\n",
       " -120.782958984375,\n",
       " -140.3470458984375,\n",
       " -143.23377990722656,\n",
       " -101.05603790283203,\n",
       " -126.29930877685547,\n",
       " -152.5076141357422,\n",
       " -113.88152313232422,\n",
       " -138.7554168701172,\n",
       " -128.05062866210938,\n",
       " -125.19544982910156,\n",
       " -109.28762817382812,\n",
       " -147.24781799316406,\n",
       " -154.7061767578125,\n",
       " -134.69020080566406,\n",
       " -109.3580551147461,\n",
       " -86.42384338378906,\n",
       " -96.55612182617188,\n",
       " -87.77727508544922,\n",
       " -102.98005676269531,\n",
       " -122.59254455566406,\n",
       " -134.0203399658203,\n",
       " -137.7764434814453,\n",
       " -110.40061950683594,\n",
       " -123.78384399414062,\n",
       " -132.2798614501953,\n",
       " -109.84744262695312,\n",
       " -162.69749450683594,\n",
       " -129.13720703125,\n",
       " -142.1240997314453,\n",
       " -148.5015411376953,\n",
       " -103.39198303222656,\n",
       " -132.73275756835938,\n",
       " -113.9697265625,\n",
       " -107.05192565917969,\n",
       " -128.11976623535156,\n",
       " -93.11842346191406,\n",
       " -136.94004821777344,\n",
       " -134.04042053222656,\n",
       " -134.21636962890625,\n",
       " -119.64887237548828,\n",
       " -126.46585845947266,\n",
       " -96.27812194824219,\n",
       " -109.39229583740234,\n",
       " -93.44377899169922,\n",
       " -113.02523040771484,\n",
       " -116.98247528076172,\n",
       " -116.76077270507812,\n",
       " -141.18968200683594,\n",
       " -103.4313735961914,\n",
       " -82.75984191894531,\n",
       " -91.98645782470703,\n",
       " -131.39361572265625,\n",
       " -94.4980697631836,\n",
       " -122.86165618896484,\n",
       " -119.16101837158203,\n",
       " -119.34998321533203,\n",
       " -64.9481201171875,\n",
       " -110.49003601074219,\n",
       " -110.2248306274414,\n",
       " -97.68509674072266,\n",
       " -132.90892028808594,\n",
       " -128.9062042236328,\n",
       " -111.07567596435547,\n",
       " -123.78204345703125,\n",
       " -124.2840347290039,\n",
       " -115.332763671875,\n",
       " -127.21398162841797,\n",
       " -139.1248016357422,\n",
       " -134.4208984375,\n",
       " -118.00170135498047,\n",
       " -130.1128387451172,\n",
       " -118.55055236816406,\n",
       " -132.47201538085938,\n",
       " -122.27649688720703,\n",
       " -98.05217742919922,\n",
       " -110.4188003540039,\n",
       " -128.84104919433594,\n",
       " -123.76708984375,\n",
       " -132.39402770996094,\n",
       " -97.71868133544922,\n",
       " -103.0201187133789,\n",
       " -133.77001953125,\n",
       " -116.28770446777344,\n",
       " -134.68418884277344,\n",
       " -126.54876708984375,\n",
       " -125.3858413696289,\n",
       " -135.19725036621094,\n",
       " -137.78379821777344,\n",
       " -125.03597259521484,\n",
       " -124.21553802490234,\n",
       " -133.3185272216797,\n",
       " -133.67596435546875,\n",
       " -153.91314697265625,\n",
       " -129.40350341796875,\n",
       " -123.609375,\n",
       " -131.91513061523438,\n",
       " -142.8341827392578,\n",
       " -128.97328186035156,\n",
       " -134.87765502929688,\n",
       " -116.00923156738281,\n",
       " -122.3086166381836,\n",
       " -135.28695678710938,\n",
       " -138.8931884765625,\n",
       " -136.99366760253906,\n",
       " -118.36442565917969,\n",
       " -123.19464874267578,\n",
       " -134.16920471191406,\n",
       " -152.78953552246094,\n",
       " -155.00222778320312,\n",
       " -158.1561279296875,\n",
       " -122.50659942626953,\n",
       " -127.09310913085938,\n",
       " -127.93402099609375,\n",
       " -117.5887680053711,\n",
       " -134.58592224121094,\n",
       " -126.90086364746094,\n",
       " -168.17022705078125,\n",
       " -130.82012939453125,\n",
       " -136.07437133789062,\n",
       " -114.61505889892578,\n",
       " -105.58549499511719,\n",
       " -127.95252990722656,\n",
       " -128.0046844482422,\n",
       " -103.01660919189453,\n",
       " -106.31209564208984,\n",
       " -135.21279907226562,\n",
       " -112.26924896240234,\n",
       " -95.65110778808594,\n",
       " -101.50364685058594,\n",
       " -138.9627227783203,\n",
       " -150.7218780517578,\n",
       " -152.56735229492188,\n",
       " -140.52415466308594,\n",
       " -137.84329223632812,\n",
       " -122.91053009033203,\n",
       " -140.7889862060547,\n",
       " -142.3433837890625,\n",
       " -145.27908325195312,\n",
       " -142.71751403808594,\n",
       " -131.1698455810547,\n",
       " -129.33474731445312,\n",
       " -143.48687744140625,\n",
       " -134.74717712402344,\n",
       " -124.2334976196289,\n",
       " -124.4838638305664,\n",
       " -140.0138702392578,\n",
       " -115.7703857421875,\n",
       " -148.8617706298828,\n",
       " -132.17222595214844,\n",
       " -131.72857666015625,\n",
       " -142.8859100341797,\n",
       " -125.23184204101562,\n",
       " -131.1916046142578,\n",
       " -127.9160385131836,\n",
       " -138.86814880371094,\n",
       " -118.51188659667969,\n",
       " -115.12794494628906,\n",
       " -113.68440246582031,\n",
       " -120.190673828125,\n",
       " -122.74043273925781,\n",
       " -116.04912567138672,\n",
       " -108.65324401855469,\n",
       " -152.8645782470703,\n",
       " -130.4619598388672,\n",
       " -139.41018676757812,\n",
       " -152.74415588378906,\n",
       " -140.0459747314453,\n",
       " -113.00873565673828,\n",
       " -128.11813354492188,\n",
       " -121.76946258544922,\n",
       " -133.8865203857422,\n",
       " -148.69203186035156,\n",
       " -111.70187377929688,\n",
       " -125.03740692138672,\n",
       " -115.98816680908203,\n",
       " -142.02774047851562,\n",
       " -139.8442840576172,\n",
       " -124.44287109375,\n",
       " -120.90187072753906,\n",
       " -135.3040008544922,\n",
       " -131.9740447998047,\n",
       " -117.98296356201172,\n",
       " -121.86927032470703,\n",
       " -136.33804321289062,\n",
       " -131.75491333007812,\n",
       " -141.3581085205078,\n",
       " -117.03731536865234,\n",
       " -133.8439178466797,\n",
       " -138.12832641601562,\n",
       " -117.51545715332031,\n",
       " -155.05374145507812,\n",
       " -118.91368103027344,\n",
       " -153.2313232421875,\n",
       " -118.59443664550781,\n",
       " -138.6163787841797,\n",
       " -96.57331085205078,\n",
       " -118.13995361328125,\n",
       " -129.10858154296875,\n",
       " -94.943603515625,\n",
       " -107.34537506103516,\n",
       " -119.38863372802734,\n",
       " -118.68316650390625,\n",
       " -147.11705017089844,\n",
       " -131.77464294433594,\n",
       " -129.05589294433594,\n",
       " -113.54301452636719,\n",
       " -90.34976959228516,\n",
       " -100.27880859375,\n",
       " -127.068603515625,\n",
       " -112.67562103271484,\n",
       " -141.05587768554688,\n",
       " -118.53553009033203,\n",
       " -140.45065307617188,\n",
       " -103.77503967285156,\n",
       " -111.99688720703125,\n",
       " -126.35662078857422,\n",
       " -114.35968017578125,\n",
       " -129.29286193847656,\n",
       " -128.6627655029297,\n",
       " -128.689208984375,\n",
       " -133.2290496826172,\n",
       " -107.21954345703125,\n",
       " -102.09986877441406,\n",
       " -131.03445434570312,\n",
       " -130.37924194335938,\n",
       " -153.10836791992188,\n",
       " -90.96837615966797,\n",
       " -119.51134490966797,\n",
       " -123.62919616699219,\n",
       " -125.95828247070312,\n",
       " -118.41317749023438,\n",
       " -103.8208999633789,\n",
       " -111.07942962646484,\n",
       " -134.99078369140625,\n",
       " -124.24880981445312,\n",
       " -109.10601806640625,\n",
       " -125.73063659667969,\n",
       " -137.08302307128906,\n",
       " -139.28604125976562,\n",
       " -127.19038391113281,\n",
       " -120.58506774902344,\n",
       " -142.68020629882812,\n",
       " -93.65211486816406,\n",
       " -142.25558471679688,\n",
       " -92.05352783203125,\n",
       " -131.5096435546875,\n",
       " -122.36394500732422,\n",
       " -116.7763671875,\n",
       " -137.10667419433594,\n",
       " -125.05555725097656,\n",
       " -114.4700927734375,\n",
       " -87.36309051513672,\n",
       " -101.46855926513672,\n",
       " -121.05786895751953,\n",
       " -123.40811157226562,\n",
       " -127.43622589111328,\n",
       " -112.50176239013672,\n",
       " -104.35218048095703,\n",
       " -126.91964721679688,\n",
       " -110.27522277832031,\n",
       " -101.93907928466797,\n",
       " -125.4448013305664,\n",
       " -142.28201293945312,\n",
       " -135.60174560546875,\n",
       " -133.02711486816406,\n",
       " -126.37934875488281,\n",
       " -138.44369506835938,\n",
       " -116.1399154663086,\n",
       " -107.68666076660156,\n",
       " -132.46115112304688,\n",
       " -111.76624298095703,\n",
       " -142.23631286621094,\n",
       " -132.5033721923828,\n",
       " -105.18707275390625,\n",
       " -144.93748474121094,\n",
       " -123.71064758300781,\n",
       " -101.04740905761719,\n",
       " -113.59622955322266,\n",
       " -123.66986083984375,\n",
       " -103.0583267211914,\n",
       " -118.01888275146484,\n",
       " -126.9073715209961,\n",
       " -138.23306274414062,\n",
       " -132.99256896972656,\n",
       " -98.0525894165039,\n",
       " -131.11549377441406,\n",
       " -143.88059997558594,\n",
       " -144.55722045898438,\n",
       " -135.34768676757812,\n",
       " -98.61676788330078,\n",
       " -130.43978881835938,\n",
       " -114.44926452636719,\n",
       " -104.49793243408203,\n",
       " -108.58769989013672,\n",
       " -114.12638854980469,\n",
       " -87.6432876586914,\n",
       " -123.97464752197266,\n",
       " -119.07735443115234,\n",
       " -118.47483825683594,\n",
       " -110.61961364746094,\n",
       " -100.29100036621094,\n",
       " -132.11671447753906,\n",
       " -137.54971313476562,\n",
       " -115.12646484375,\n",
       " -105.57207489013672,\n",
       " -104.67051696777344,\n",
       " -91.46660614013672,\n",
       " -110.56017303466797,\n",
       " -140.33258056640625,\n",
       " -103.12255096435547,\n",
       " -125.38216400146484,\n",
       " -141.75518798828125,\n",
       " -142.5457000732422,\n",
       " -133.10430908203125,\n",
       " -110.71238708496094,\n",
       " -114.50971221923828,\n",
       " -128.1441192626953,\n",
       " -104.98320007324219,\n",
       " -95.57011413574219,\n",
       " -97.227294921875,\n",
       " -109.94972229003906,\n",
       " -123.63715362548828,\n",
       " -94.81513977050781,\n",
       " -122.95526885986328,\n",
       " -106.22659301757812,\n",
       " -130.91236877441406,\n",
       " -145.35528564453125,\n",
       " -134.7558135986328,\n",
       " -134.3634796142578,\n",
       " -142.02816772460938,\n",
       " -128.66390991210938,\n",
       " -125.49226379394531,\n",
       " -128.24559020996094,\n",
       " -121.76128387451172,\n",
       " -129.48480224609375,\n",
       " -109.0964126586914,\n",
       " -117.01411437988281,\n",
       " -163.00820922851562,\n",
       " -131.62416076660156,\n",
       " -104.0337142944336,\n",
       " -111.00373840332031,\n",
       " -106.61455535888672,\n",
       " -109.97099304199219,\n",
       " -119.12939453125,\n",
       " -127.65575408935547,\n",
       " -121.11760711669922,\n",
       " -135.70614624023438,\n",
       " -124.84471130371094,\n",
       " -123.94989013671875,\n",
       " -134.4081573486328,\n",
       " -88.84742736816406,\n",
       " -129.49209594726562,\n",
       " -142.5398406982422,\n",
       " -117.45153045654297,\n",
       " -118.82684326171875,\n",
       " -100.32072448730469,\n",
       " -132.16323852539062,\n",
       " -139.25926208496094,\n",
       " -155.0832061767578,\n",
       " -135.65899658203125,\n",
       " -129.185791015625,\n",
       " -147.1866455078125,\n",
       " -109.95794677734375,\n",
       " -118.76248168945312,\n",
       " -120.47095489501953,\n",
       " -100.83198547363281,\n",
       " -115.82532501220703,\n",
       " -115.31124114990234,\n",
       " -108.55105590820312,\n",
       " -119.81578826904297,\n",
       " -117.36356353759766,\n",
       " -108.34951782226562,\n",
       " -138.54946899414062,\n",
       " -100.871826171875,\n",
       " -116.66194152832031,\n",
       " -141.10423278808594,\n",
       " -111.55482482910156,\n",
       " -105.913818359375,\n",
       " -130.59591674804688,\n",
       " -145.19900512695312,\n",
       " -126.31049346923828,\n",
       " -150.135498046875,\n",
       " -135.94602966308594,\n",
       " -117.23591613769531,\n",
       " 76.01236724853516,\n",
       " -117.86860656738281,\n",
       " -134.1752471923828,\n",
       " -120.18061828613281,\n",
       " -140.7585906982422,\n",
       " -130.70928955078125,\n",
       " -128.6334686279297,\n",
       " -128.95693969726562,\n",
       " -141.45321655273438,\n",
       " -139.8865509033203,\n",
       " -110.36233520507812,\n",
       " -96.429443359375,\n",
       " -143.9715576171875,\n",
       " -118.04520416259766,\n",
       " -113.03372955322266,\n",
       " -108.3582763671875,\n",
       " -109.02090454101562,\n",
       " -99.42542266845703,\n",
       " -126.76033020019531,\n",
       " -111.80302429199219,\n",
       " -96.50121307373047,\n",
       " -109.0617904663086,\n",
       " -135.68991088867188,\n",
       " -115.20816802978516,\n",
       " 72.6466064453125,\n",
       " -106.57967376708984,\n",
       " -112.96269989013672,\n",
       " -108.99092102050781,\n",
       " -98.03846740722656,\n",
       " -123.74131774902344,\n",
       " -110.26152801513672,\n",
       " -96.71724700927734,\n",
       " -143.32318115234375,\n",
       " -110.07077026367188,\n",
       " -126.84832763671875,\n",
       " -123.25567626953125,\n",
       " -127.61212921142578,\n",
       " -137.0795135498047,\n",
       " -136.52435302734375,\n",
       " -110.6116714477539,\n",
       " -141.798095703125,\n",
       " -118.22132873535156,\n",
       " -132.2318115234375,\n",
       " -103.83821868896484,\n",
       " -120.04801177978516,\n",
       " -126.13642120361328,\n",
       " -120.47438049316406,\n",
       " -144.16165161132812,\n",
       " -127.92369842529297,\n",
       " -116.99359130859375]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr.',\n",
       " 'tilly',\n",
       " 'had',\n",
       " 'only',\n",
       " 'the',\n",
       " 'briefest',\n",
       " 'moment',\n",
       " 'for',\n",
       " 'reflection,',\n",
       " 'when,',\n",
       " 'as',\n",
       " 'he',\n",
       " 'slipped',\n",
       " 'and',\n",
       " 'fell',\n",
       " 'on',\n",
       " 'the',\n",
       " 'greasy',\n",
       " 'wood',\n",
       " 'pavement',\n",
       " 'at',\n",
       " 'hyde',\n",
       " 'park',\n",
       " 'corner,',\n",
       " 'which',\n",
       " 'he',\n",
       " 'was',\n",
       " 'crossing',\n",
       " 'at',\n",
       " 'a',\n",
       " 'smart',\n",
       " 'trot,',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'huge',\n",
       " 'traction-engine',\n",
       " 'with',\n",
       " 'its',\n",
       " 'grooved',\n",
       " 'ponderous',\n",
       " 'wheels',\n",
       " 'towering',\n",
       " 'high',\n",
       " 'above',\n",
       " 'him.',\n",
       " 'oh,',\n",
       " 'dear!',\n",
       " 'oh,',\n",
       " 'dear!',\n",
       " 'he',\n",
       " 'said',\n",
       " 'petulantly,',\n",
       " 'it',\n",
       " 'will',\n",
       " 'certainly',\n",
       " 'crush',\n",
       " 'me',\n",
       " 'quite',\n",
       " 'flat,',\n",
       " 'and',\n",
       " 'i',\n",
       " 'shant',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'be',\n",
       " 'at',\n",
       " 'mrs.',\n",
       " 'cumberbatchs',\n",
       " 'sance!',\n",
       " 'most',\n",
       " 'provoking!',\n",
       " 'a-ow!',\n",
       " 'the',\n",
       " 'words',\n",
       " 'were',\n",
       " 'hardly',\n",
       " 'out',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mouth,',\n",
       " 'when',\n",
       " 'the',\n",
       " 'first',\n",
       " 'half',\n",
       " 'of',\n",
       " 'his',\n",
       " 'horrid',\n",
       " 'anticipations',\n",
       " 'was',\n",
       " 'thoroughly',\n",
       " 'fulfilled.',\n",
       " 'the',\n",
       " 'heavy',\n",
       " 'wheels',\n",
       " 'passed',\n",
       " 'over',\n",
       " 'him',\n",
       " 'from',\n",
       " 'head',\n",
       " 'to',\n",
       " 'foot',\n",
       " 'and',\n",
       " 'flattened',\n",
       " 'him',\n",
       " 'completely',\n",
       " 'out.',\n",
       " 'then',\n",
       " 'the',\n",
       " 'driver',\n",
       " '(too',\n",
       " 'late)',\n",
       " 'reversed',\n",
       " 'his',\n",
       " 'engine',\n",
       " 'and',\n",
       " 'passed',\n",
       " 'over',\n",
       " 'him',\n",
       " 'again,',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'lost',\n",
       " 'his',\n",
       " 'head,',\n",
       " 'whistled',\n",
       " 'loudly',\n",
       " 'and',\n",
       " 'stopped.',\n",
       " 'the',\n",
       " 'policeman',\n",
       " 'on',\n",
       " 'duty',\n",
       " 'at',\n",
       " 'the',\n",
       " 'corner',\n",
       " 'turned',\n",
       " 'quite',\n",
       " 'faint',\n",
       " 'at',\n",
       " 'the',\n",
       " 'sight',\n",
       " 'of',\n",
       " 'the',\n",
       " 'catastrophe,',\n",
       " 'but',\n",
       " 'presently',\n",
       " 'recovered',\n",
       " 'sufficiently',\n",
       " 'to',\n",
       " 'hold',\n",
       " 'up',\n",
       " 'the',\n",
       " 'traffic,',\n",
       " 'and',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'see',\n",
       " 'what',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'could',\n",
       " 'be',\n",
       " 'done.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'so',\n",
       " 'much',\n",
       " 'up',\n",
       " 'with',\n",
       " 'mr.',\n",
       " 'tilly',\n",
       " 'that',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'possible',\n",
       " 'was',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'hysterical',\n",
       " 'engine-driver',\n",
       " 'to',\n",
       " 'move',\n",
       " 'clear.',\n",
       " 'then',\n",
       " 'the',\n",
       " 'ambulance',\n",
       " 'from',\n",
       " 'the',\n",
       " 'hospital',\n",
       " 'was',\n",
       " 'sent',\n",
       " 'for,',\n",
       " 'and',\n",
       " 'mr.',\n",
       " 'tillys',\n",
       " 'remains,',\n",
       " 'detached',\n",
       " 'with',\n",
       " 'great',\n",
       " 'difficulty',\n",
       " 'from',\n",
       " 'the',\n",
       " 'road',\n",
       " '(so',\n",
       " 'firmly',\n",
       " 'had',\n",
       " 'they',\n",
       " 'been',\n",
       " 'pressed',\n",
       " 'into',\n",
       " 'it),',\n",
       " 'were',\n",
       " 'reverently',\n",
       " 'carried',\n",
       " 'away',\n",
       " 'into',\n",
       " 'the',\n",
       " 'mortuary.',\n",
       " 'mr.',\n",
       " 'tilly',\n",
       " 'during',\n",
       " 'this',\n",
       " 'had',\n",
       " 'experienced',\n",
       " 'one',\n",
       " 'moments',\n",
       " 'excruciating',\n",
       " 'pain,',\n",
       " 'resembling',\n",
       " 'the',\n",
       " 'severest',\n",
       " 'neuralgia',\n",
       " 'as',\n",
       " 'his',\n",
       " 'head',\n",
       " 'was',\n",
       " 'ground',\n",
       " 'beneath',\n",
       " 'the',\n",
       " 'wheel,',\n",
       " 'but',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'he',\n",
       " 'realised',\n",
       " 'it,',\n",
       " 'the',\n",
       " 'pain',\n",
       " 'was',\n",
       " 'past,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'found',\n",
       " 'himself,',\n",
       " 'still',\n",
       " 'rather',\n",
       " 'dazed,',\n",
       " 'floating',\n",
       " 'or',\n",
       " 'standing',\n",
       " '(he',\n",
       " 'did',\n",
       " 'no',\n",
       " 'know',\n",
       " 'which)',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'the',\n",
       " 'road.',\n",
       " 'there',\n",
       " 'had',\n",
       " 'been',\n",
       " 'no',\n",
       " 'break',\n",
       " 'in',\n",
       " 'his',\n",
       " 'consciousness;',\n",
       " 'he',\n",
       " 'perfectly',\n",
       " 'recollected',\n",
       " 'slipping,',\n",
       " 'and',\n",
       " 'wondered',\n",
       " 'how',\n",
       " 'he',\n",
       " 'had',\n",
       " 'managed',\n",
       " 'to',\n",
       " 'save',\n",
       " 'himself.',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'arrested',\n",
       " 'traffic,',\n",
       " 'the',\n",
       " 'policeman',\n",
       " 'with',\n",
       " 'white',\n",
       " 'wan',\n",
       " 'face',\n",
       " 'making',\n",
       " 'suggestions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'gibbering',\n",
       " 'engine-driver,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'received',\n",
       " 'the',\n",
       " 'very',\n",
       " 'puzzling',\n",
       " 'impression',\n",
       " 'that',\n",
       " 'the',\n",
       " 'traction',\n",
       " 'engine',\n",
       " 'was',\n",
       " 'all',\n",
       " 'mixed',\n",
       " 'up',\n",
       " 'with',\n",
       " 'him.',\n",
       " 'he',\n",
       " 'had',\n",
       " 'a',\n",
       " 'sensation',\n",
       " 'of',\n",
       " 'red-hot',\n",
       " 'coals',\n",
       " 'and',\n",
       " 'boiling',\n",
       " 'water',\n",
       " 'and',\n",
       " 'rivets',\n",
       " 'all',\n",
       " 'around',\n",
       " 'him,',\n",
       " 'but',\n",
       " 'yet',\n",
       " 'no',\n",
       " 'feeling',\n",
       " 'of',\n",
       " 'scalding',\n",
       " 'or',\n",
       " 'burning',\n",
       " 'or',\n",
       " 'confinement.',\n",
       " 'he',\n",
       " 'was,',\n",
       " 'on',\n",
       " 'the',\n",
       " 'contrary,',\n",
       " 'extremely',\n",
       " 'comfortable,',\n",
       " 'and',\n",
       " 'had',\n",
       " 'the',\n",
       " 'most',\n",
       " 'pleasant',\n",
       " 'consciousness',\n",
       " 'of',\n",
       " 'buoyancy',\n",
       " 'and',\n",
       " 'freedom.',\n",
       " 'then',\n",
       " 'the',\n",
       " 'engine',\n",
       " 'puffed',\n",
       " 'and',\n",
       " 'the',\n",
       " 'wheels',\n",
       " 'went',\n",
       " 'round,',\n",
       " 'and',\n",
       " 'immediately,',\n",
       " 'to',\n",
       " 'his',\n",
       " 'immense',\n",
       " 'surprise,',\n",
       " 'he',\n",
       " 'perceived',\n",
       " 'his',\n",
       " 'own',\n",
       " 'crushed',\n",
       " 'remains,',\n",
       " 'flat',\n",
       " 'as',\n",
       " 'a',\n",
       " 'biscuit,',\n",
       " 'lying',\n",
       " 'on',\n",
       " 'the',\n",
       " 'roadway.',\n",
       " 'he',\n",
       " 'identified',\n",
       " 'them',\n",
       " 'for',\n",
       " 'certain',\n",
       " 'by',\n",
       " 'his',\n",
       " 'clothes,',\n",
       " 'which',\n",
       " 'he',\n",
       " 'had',\n",
       " 'put',\n",
       " 'on',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'that',\n",
       " 'morning,',\n",
       " 'and',\n",
       " 'one',\n",
       " 'patent',\n",
       " 'leather',\n",
       " 'boot',\n",
       " 'which',\n",
       " 'had',\n",
       " 'escaped',\n",
       " 'demolition.',\n",
       " 'but',\n",
       " 'what',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'has',\n",
       " 'happened?',\n",
       " 'he',\n",
       " 'said.',\n",
       " 'here',\n",
       " 'am',\n",
       " 'i,',\n",
       " 'and',\n",
       " 'yet',\n",
       " 'that',\n",
       " 'poor',\n",
       " 'pressed',\n",
       " 'flower',\n",
       " 'of',\n",
       " 'arms',\n",
       " 'and',\n",
       " 'legs',\n",
       " 'is',\n",
       " 'me',\n",
       " '',\n",
       " 'or',\n",
       " 'rather',\n",
       " 'i',\n",
       " 'also.',\n",
       " 'and',\n",
       " 'how',\n",
       " 'terribly',\n",
       " 'upset',\n",
       " 'the',\n",
       " 'driver',\n",
       " 'looks.',\n",
       " 'why,',\n",
       " 'i',\n",
       " 'do',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'run',\n",
       " 'over!',\n",
       " 'it',\n",
       " 'did',\n",
       " 'hurt',\n",
       " 'for',\n",
       " 'a',\n",
       " 'moment,',\n",
       " 'now',\n",
       " 'i',\n",
       " 'come',\n",
       " 'to',\n",
       " 'think',\n",
       " 'of',\n",
       " 'it...',\n",
       " 'my',\n",
       " 'good',\n",
       " 'man,',\n",
       " 'where',\n",
       " 'are',\n",
       " 'you',\n",
       " 'shoving',\n",
       " 'to?',\n",
       " 'dont',\n",
       " 'you',\n",
       " 'see',\n",
       " 'me?',\n",
       " 'he',\n",
       " 'addressed',\n",
       " 'these',\n",
       " 'two',\n",
       " 'questions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'policeman,',\n",
       " 'who',\n",
       " 'appeared',\n",
       " 'to',\n",
       " 'walk',\n",
       " 'right',\n",
       " 'through',\n",
       " 'him.',\n",
       " 'but',\n",
       " 'the',\n",
       " 'man',\n",
       " 'took',\n",
       " 'no',\n",
       " 'notice,',\n",
       " 'and',\n",
       " 'calmly',\n",
       " 'came',\n",
       " 'out',\n",
       " 'on',\n",
       " 'the',\n",
       " 'other',\n",
       " 'side:',\n",
       " 'it',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'evident',\n",
       " 'that',\n",
       " 'he',\n",
       " 'did',\n",
       " 'not',\n",
       " 'see',\n",
       " 'him,',\n",
       " 'or',\n",
       " 'apprehend',\n",
       " 'him',\n",
       " 'in',\n",
       " 'any',\n",
       " 'way.',\n",
       " 'mr.',\n",
       " 'tilly',\n",
       " 'was',\n",
       " 'still',\n",
       " 'feeling',\n",
       " 'rather',\n",
       " 'at',\n",
       " 'sea',\n",
       " 'amid',\n",
       " 'these',\n",
       " 'unusual',\n",
       " 'occurrences,',\n",
       " 'and',\n",
       " 'there',\n",
       " 'began',\n",
       " 'to',\n",
       " 'steal',\n",
       " 'into',\n",
       " 'his',\n",
       " 'mind',\n",
       " 'a',\n",
       " 'glimpse',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'which',\n",
       " 'was',\n",
       " 'so',\n",
       " 'obvious',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crowd',\n",
       " 'which',\n",
       " 'formed',\n",
       " 'an',\n",
       " 'interested',\n",
       " 'but',\n",
       " 'respectful',\n",
       " 'ring',\n",
       " 'round',\n",
       " 'his',\n",
       " 'body.',\n",
       " 'men',\n",
       " 'stood',\n",
       " 'with',\n",
       " 'bared',\n",
       " 'heads;',\n",
       " 'women',\n",
       " 'screamed',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'away',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'back',\n",
       " 'again.',\n",
       " 'i',\n",
       " 'really',\n",
       " 'believe',\n",
       " 'im',\n",
       " 'dead,',\n",
       " 'said',\n",
       " 'he.',\n",
       " 'thats',\n",
       " 'the',\n",
       " 'only',\n",
       " 'hypothesis',\n",
       " 'which',\n",
       " 'will',\n",
       " 'cover',\n",
       " 'the',\n",
       " 'facts.',\n",
       " 'but',\n",
       " 'i',\n",
       " 'must',\n",
       " 'feel',\n",
       " 'more',\n",
       " 'certain',\n",
       " 'of',\n",
       " 'it',\n",
       " 'before',\n",
       " 'i',\n",
       " 'do',\n",
       " 'anything.',\n",
       " 'ah!',\n",
       " 'here',\n",
       " 'they',\n",
       " 'come',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ambulance',\n",
       " 'to',\n",
       " 'look',\n",
       " 'at',\n",
       " 'me.',\n",
       " 'i',\n",
       " 'must',\n",
       " 'be',\n",
       " 'terribly',\n",
       " 'hurt,',\n",
       " 'and',\n",
       " 'yet',\n",
       " 'i',\n",
       " 'dont',\n",
       " 'feel',\n",
       " 'hurt.',\n",
       " 'i',\n",
       " 'should',\n",
       " 'feel',\n",
       " 'hurt',\n",
       " 'surely',\n",
       " 'if',\n",
       " 'i',\n",
       " 'was',\n",
       " 'hurt.',\n",
       " 'i',\n",
       " 'must',\n",
       " 'be',\n",
       " 'dead.',\n",
       " 'certainly',\n",
       " 'it',\n",
       " 'seemed',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'for',\n",
       " 'him',\n",
       " 'to',\n",
       " 'be,',\n",
       " 'but',\n",
       " 'he',\n",
       " 'was',\n",
       " 'far',\n",
       " 'from',\n",
       " 'realising',\n",
       " 'it',\n",
       " 'yet.',\n",
       " 'a',\n",
       " 'lane',\n",
       " 'had',\n",
       " 'been',\n",
       " 'made',\n",
       " 'through',\n",
       " 'the',\n",
       " 'crowd',\n",
       " 'for',\n",
       " 'the',\n",
       " 'stretcher-bearers,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'found',\n",
       " 'himself',\n",
       " 'wincing',\n",
       " 'when',\n",
       " 'they',\n",
       " 'began',\n",
       " 'to',\n",
       " 'detach',\n",
       " 'him',\n",
       " 'from',\n",
       " 'the',\n",
       " 'road.',\n",
       " 'oh,',\n",
       " 'do',\n",
       " 'take',\n",
       " 'care!',\n",
       " 'he',\n",
       " 'said.',\n",
       " 'thats',\n",
       " 'the',\n",
       " 'sciatic',\n",
       " 'nerve',\n",
       " 'protruding',\n",
       " 'there',\n",
       " 'surely,',\n",
       " 'isnt',\n",
       " 'it?',\n",
       " 'a-ow!',\n",
       " 'no,',\n",
       " 'it',\n",
       " 'didnt',\n",
       " 'hurt',\n",
       " 'after',\n",
       " 'all.',\n",
       " 'my',\n",
       " 'new',\n",
       " 'clothes,',\n",
       " 'too:',\n",
       " 'i',\n",
       " 'put',\n",
       " 'them',\n",
       " 'on',\n",
       " 'today',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time.',\n",
       " 'what',\n",
       " 'bad',\n",
       " 'luck!',\n",
       " 'now',\n",
       " 'youre',\n",
       " 'holding',\n",
       " 'my',\n",
       " 'leg',\n",
       " 'upside',\n",
       " 'down.',\n",
       " 'of',\n",
       " 'course',\n",
       " 'all',\n",
       " 'my',\n",
       " 'money',\n",
       " 'comes',\n",
       " 'out',\n",
       " 'of',\n",
       " 'my',\n",
       " 'trouser',\n",
       " 'pocket.',\n",
       " 'and',\n",
       " 'theres',\n",
       " 'my',\n",
       " 'ticket',\n",
       " 'for',\n",
       " 'the',\n",
       " 'sance;',\n",
       " 'i',\n",
       " 'must',\n",
       " 'have',\n",
       " 'that:',\n",
       " 'i',\n",
       " 'may',\n",
       " 'use',\n",
       " 'it',\n",
       " 'after',\n",
       " 'all.',\n",
       " 'he',\n",
       " 'tweaked',\n",
       " 'it',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fingers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'man',\n",
       " 'who',\n",
       " 'had',\n",
       " 'picked',\n",
       " 'it',\n",
       " 'up,',\n",
       " 'and',\n",
       " 'laughed',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'expression',\n",
       " 'of',\n",
       " 'amazement',\n",
       " 'on',\n",
       " 'his',\n",
       " 'face',\n",
       " 'as',\n",
       " 'the',\n",
       " 'card',\n",
       " 'suddenly',\n",
       " 'vanished.',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'him',\n",
       " 'something',\n",
       " 'fresh',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'pondered',\n",
       " 'for',\n",
       " 'a',\n",
       " 'moment',\n",
       " 'over',\n",
       " 'some',\n",
       " 'touch',\n",
       " 'of',\n",
       " 'association',\n",
       " 'set',\n",
       " 'up',\n",
       " 'by',\n",
       " 'it.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'it,',\n",
       " 'he',\n",
       " 'thought.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'i',\n",
       " 'came',\n",
       " 'into',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'that',\n",
       " 'card,',\n",
       " 'it',\n",
       " 'became',\n",
       " 'invisible.',\n",
       " 'im',\n",
       " 'invisible',\n",
       " 'myself',\n",
       " '(of',\n",
       " 'course',\n",
       " 'to',\n",
       " 'the',\n",
       " 'grosser',\n",
       " 'sense),',\n",
       " 'and',\n",
       " 'everything',\n",
       " 'i',\n",
       " 'hold',\n",
       " 'becomes',\n",
       " 'invisible.',\n",
       " 'most',\n",
       " 'interesting!',\n",
       " 'that',\n",
       " 'accounts',\n",
       " 'for',\n",
       " 'the',\n",
       " 'sudden',\n",
       " 'appearances',\n",
       " 'of',\n",
       " 'small',\n",
       " 'objects',\n",
       " 'at',\n",
       " 'a',\n",
       " 'sance.',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'has',\n",
       " 'been',\n",
       " 'holding',\n",
       " 'them,',\n",
       " 'and',\n",
       " 'as',\n",
       " 'long',\n",
       " 'as',\n",
       " 'he',\n",
       " 'holds',\n",
       " 'them',\n",
       " 'they',\n",
       " 'are',\n",
       " 'invisible.',\n",
       " 'then',\n",
       " 'he',\n",
       " 'lets',\n",
       " 'go,',\n",
       " 'and',\n",
       " 'theres',\n",
       " 'the',\n",
       " 'flower',\n",
       " 'or',\n",
       " 'the',\n",
       " 'spirit-photograph',\n",
       " 'on',\n",
       " 'the',\n",
       " 'table.',\n",
       " 'it',\n",
       " 'accounts,',\n",
       " 'too,',\n",
       " 'for',\n",
       " 'the',\n",
       " 'sudden',\n",
       " 'disappearances',\n",
       " 'of',\n",
       " 'such',\n",
       " 'objects.',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'has',\n",
       " 'taken',\n",
       " 'them,',\n",
       " 'though',\n",
       " 'the',\n",
       " 'scoffers',\n",
       " 'say',\n",
       " 'that',\n",
       " 'the',\n",
       " 'medium',\n",
       " 'has',\n",
       " 'secreted',\n",
       " 'them',\n",
       " 'about',\n",
       " 'his',\n",
       " 'person.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'true',\n",
       " 'that',\n",
       " 'when',\n",
       " 'searched',\n",
       " 'he',\n",
       " 'sometimes',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'have',\n",
       " 'done',\n",
       " 'so;',\n",
       " 'but,',\n",
       " 'after',\n",
       " 'all,',\n",
       " 'that',\n",
       " 'may',\n",
       " 'be',\n",
       " 'a',\n",
       " 'joke',\n",
       " 'on',\n",
       " 'the',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'spirit.',\n",
       " 'now,',\n",
       " 'what',\n",
       " 'am',\n",
       " 'i',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'myself.',\n",
       " 'let',\n",
       " 'me',\n",
       " 'see,',\n",
       " 'theres',\n",
       " 'the',\n",
       " 'clock.',\n",
       " 'its',\n",
       " 'just',\n",
       " 'half-past',\n",
       " 'ten.',\n",
       " 'all',\n",
       " 'this',\n",
       " 'has',\n",
       " 'happened',\n",
       " 'in',\n",
       " 'a',\n",
       " 'few',\n",
       " 'minutes,',\n",
       " 'for',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'quarter',\n",
       " 'past',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at C:\\Users\\Hao Lu User\\.cache\\torch\\pytorch_transformers\\4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import string\n",
    "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set the model in evaluation mode to desactivate the DropOut modules\n",
    "# This is IMPORTANT to have reproductible results during evaluation!\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the story and split word\n",
    "file1 = open(\"MrTillysSeance_reformatted.txt\",\"r\",encoding='UTF-8') \n",
    "story = file1.readlines()\n",
    "story_list = story[0].split()\n",
    "\n",
    "# Initialize the list to store weights\n",
    "next_weight = []\n",
    "\n",
    "# the loop is from 5th word to last word so the first prediction has some context\n",
    "for iWord in range(5,len(story_list)):\n",
    "    \n",
    "    next_word = story_list[iWord].translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    if next_word:\n",
    "        if (iWord - 200>=0):\n",
    "            context_word = story_list[(iWord-200):(iWord-1)]\n",
    "        else:\n",
    "            context_word = story_list[0:(iWord-1)]\n",
    "        seperator = ' '\n",
    "        text = seperator.join(context_word)\n",
    "    \n",
    "    # Encode a text inputs\n",
    "        indexed_tokens = tokenizer.encode(text)\n",
    "    \n",
    "    # Convert indexed tokens in a PyTorch tensor\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    \n",
    "    # If you have a GPU, put everything on cuda\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        model.to('cuda')\n",
    "    \n",
    "    # Predict all tokens\n",
    "    # output[0] is the weight of last layer\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        # get the weight for the predicted last word\n",
    "        next_weight.append(predictions[0, -1, tokenizer.encode(next_word)[0]].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-126.09825134277344,\n",
       " -100.10073852539062,\n",
       " -122.89671325683594,\n",
       " -92.61870574951172,\n",
       " -95.12271118164062,\n",
       " -111.24650573730469,\n",
       " -132.4564971923828,\n",
       " -111.90289306640625,\n",
       " -125.08509826660156,\n",
       " -128.58102416992188,\n",
       " -121.17620849609375,\n",
       " -113.27363586425781,\n",
       " -56.63973617553711,\n",
       " -94.61131286621094,\n",
       " -87.76190948486328,\n",
       " -74.23797607421875,\n",
       " -92.42113494873047,\n",
       " -70.68011474609375,\n",
       " -67.19322204589844,\n",
       " -58.317588806152344,\n",
       " -87.98904418945312,\n",
       " -100.28479766845703,\n",
       " -137.83151245117188,\n",
       " -128.86183166503906,\n",
       " -106.28443908691406,\n",
       " -98.1455078125,\n",
       " -114.55773162841797,\n",
       " -95.46464538574219,\n",
       " -94.04417419433594,\n",
       " -129.48626708984375,\n",
       " -92.7576904296875,\n",
       " -96.01771545410156,\n",
       " -88.12798309326172,\n",
       " -91.94256591796875,\n",
       " -69.96968078613281,\n",
       " -86.54251098632812,\n",
       " -92.71683502197266,\n",
       " -104.69353485107422,\n",
       " -104.33226013183594,\n",
       " -120.29077911376953,\n",
       " -101.93157958984375,\n",
       " -84.66202545166016,\n",
       " -143.64869689941406,\n",
       " -107.91956329345703,\n",
       " -125.82865905761719,\n",
       " -94.26329040527344,\n",
       " -109.42904663085938,\n",
       " -128.946533203125,\n",
       " -95.84485626220703,\n",
       " -109.94476318359375,\n",
       " -110.52013397216797,\n",
       " -128.89468383789062,\n",
       " -125.99223327636719,\n",
       " -120.08504486083984,\n",
       " -134.77996826171875,\n",
       " -139.46578979492188,\n",
       " -121.76451110839844,\n",
       " -135.95716857910156,\n",
       " -149.2635040283203,\n",
       " -129.2499237060547,\n",
       " -129.17669677734375,\n",
       " 51.238922119140625,\n",
       " -146.6055908203125,\n",
       " -129.74632263183594,\n",
       " -88.84127807617188,\n",
       " -56.51087951660156,\n",
       " -117.45026397705078,\n",
       " -126.08020782470703,\n",
       " -100.83876037597656,\n",
       " -121.26282501220703,\n",
       " -115.81846618652344,\n",
       " -95.3812484741211,\n",
       " -119.5578384399414,\n",
       " -123.9222183227539,\n",
       " -133.41131591796875,\n",
       " -39.16700744628906,\n",
       " -86.17389678955078,\n",
       " -109.39168548583984,\n",
       " -109.03120422363281,\n",
       " -65.33547973632812,\n",
       " -97.46817016601562,\n",
       " -94.60160064697266,\n",
       " -61.36445236206055,\n",
       " -67.51846313476562,\n",
       " -117.3914566040039,\n",
       " -102.83556365966797,\n",
       " -122.05023193359375,\n",
       " -132.8690643310547,\n",
       " -136.105224609375,\n",
       " -137.32427978515625,\n",
       " -92.13504028320312,\n",
       " -94.8018798828125,\n",
       " -100.87727355957031,\n",
       " -122.01892852783203,\n",
       " -77.02838897705078,\n",
       " -113.51824188232422,\n",
       " -102.31869506835938,\n",
       " -11.644680976867676,\n",
       " -59.59511184692383,\n",
       " -95.3329086303711,\n",
       " -132.56138610839844,\n",
       " -114.33531188964844,\n",
       " -127.39002990722656,\n",
       " -120.3198013305664,\n",
       " -140.29684448242188,\n",
       " -104.98361206054688,\n",
       " -99.3241195678711,\n",
       " -128.5956573486328,\n",
       " -108.93257141113281,\n",
       " -128.80221557617188,\n",
       " -121.95612335205078,\n",
       " -108.08670043945312,\n",
       " -106.0704116821289,\n",
       " -130.98019409179688,\n",
       " -108.1742935180664,\n",
       " -73.1929931640625,\n",
       " -111.13768005371094,\n",
       " -119.58038330078125,\n",
       " -138.35084533691406,\n",
       " -131.9945526123047,\n",
       " -96.97657775878906,\n",
       " -111.53763580322266,\n",
       " -121.0159683227539,\n",
       " -99.5181884765625,\n",
       " -83.08236694335938,\n",
       " -117.4521484375,\n",
       " -147.3350372314453,\n",
       " -100.48878479003906,\n",
       " -131.1486358642578,\n",
       " -64.05378723144531,\n",
       " -125.50526428222656,\n",
       " -80.12173461914062,\n",
       " -108.43946075439453,\n",
       " -120.0488510131836,\n",
       " -119.83157348632812,\n",
       " -126.60711669921875,\n",
       " -100.31529998779297,\n",
       " -95.11034393310547,\n",
       " -116.39932250976562,\n",
       " -4.1477885246276855,\n",
       " -84.87273406982422,\n",
       " -105.42639923095703,\n",
       " -106.65149688720703,\n",
       " -135.94627380371094,\n",
       " -135.68829345703125,\n",
       " -95.2302017211914,\n",
       " -96.23464965820312,\n",
       " -156.51193237304688,\n",
       " -109.51313018798828,\n",
       " -61.39175796508789,\n",
       " -116.94878387451172,\n",
       " -115.78591918945312,\n",
       " -136.45298767089844,\n",
       " -144.69525146484375,\n",
       " -109.07833099365234,\n",
       " -112.29816436767578,\n",
       " -115.84422302246094,\n",
       " -72.80912780761719,\n",
       " -91.66902923583984,\n",
       " -74.02983093261719,\n",
       " -98.41497039794922,\n",
       " -130.971923828125,\n",
       " -98.75251770019531,\n",
       " -126.4514389038086,\n",
       " -122.66445922851562,\n",
       " -108.50401306152344,\n",
       " -111.95097351074219,\n",
       " -99.63334655761719,\n",
       " -102.74158477783203,\n",
       " -52.937652587890625,\n",
       " -89.58992767333984,\n",
       " -103.51641845703125,\n",
       " -103.66242980957031,\n",
       " -119.51756286621094,\n",
       " -118.10405731201172,\n",
       " -99.0010986328125,\n",
       " -66.19465637207031,\n",
       " -145.90863037109375,\n",
       " -133.2567596435547,\n",
       " -113.19168853759766,\n",
       " -111.62347412109375,\n",
       " -129.60287475585938,\n",
       " -140.2079315185547,\n",
       " -150.50692749023438,\n",
       " -150.45736694335938,\n",
       " -114.94690704345703,\n",
       " -106.67929077148438,\n",
       " -118.32740783691406,\n",
       " -86.00830841064453,\n",
       " -111.73690032958984,\n",
       " -120.38675689697266,\n",
       " -142.6283416748047,\n",
       " -121.27884674072266,\n",
       " -112.92064666748047,\n",
       " -129.68223571777344,\n",
       " -36.97025680541992,\n",
       " -116.79006958007812,\n",
       " -124.41896057128906,\n",
       " -103.74937438964844,\n",
       " -82.986572265625,\n",
       " -105.3434829711914,\n",
       " -100.7445297241211,\n",
       " -77.69957733154297,\n",
       " -115.19280242919922,\n",
       " -98.04795837402344,\n",
       " -101.20044708251953,\n",
       " -130.80001831054688,\n",
       " -76.03067779541016,\n",
       " -130.85328674316406,\n",
       " -145.07431030273438,\n",
       " -128.6728057861328,\n",
       " -102.17967224121094,\n",
       " -126.86445617675781,\n",
       " -128.8551483154297,\n",
       " -136.99449157714844,\n",
       " -127.30451965332031,\n",
       " -106.00470733642578,\n",
       " -66.21974182128906,\n",
       " -114.21129608154297,\n",
       " -138.35800170898438,\n",
       " -40.105926513671875,\n",
       " -102.43194580078125,\n",
       " -81.25175476074219,\n",
       " -107.44352722167969,\n",
       " -108.5158462524414,\n",
       " -104.29499816894531,\n",
       " -85.4554214477539,\n",
       " -99.5154037475586,\n",
       " -108.89046478271484,\n",
       " -98.28468322753906,\n",
       " -70.96416473388672,\n",
       " -99.15467071533203,\n",
       " -95.62896728515625,\n",
       " -86.66108703613281,\n",
       " -98.93924713134766,\n",
       " -107.88497161865234,\n",
       " -102.38113403320312,\n",
       " -119.19166564941406,\n",
       " -108.12894439697266,\n",
       " -76.09996032714844,\n",
       " -103.95327758789062,\n",
       " -108.09285736083984,\n",
       " -128.36212158203125,\n",
       " -123.13642120361328,\n",
       " -104.05729675292969,\n",
       " -144.6031036376953,\n",
       " -93.92073059082031,\n",
       " -112.87980651855469,\n",
       " -102.28018188476562,\n",
       " -112.89167785644531,\n",
       " -129.84197998046875,\n",
       " -103.55876922607422,\n",
       " -125.42221069335938,\n",
       " -128.70025634765625,\n",
       " -89.82763671875,\n",
       " -131.25283813476562,\n",
       " -104.1319580078125,\n",
       " -102.26107025146484,\n",
       " -113.68087768554688,\n",
       " -133.73670959472656,\n",
       " -111.89747619628906,\n",
       " -134.74403381347656,\n",
       " -129.79017639160156,\n",
       " -97.46359252929688,\n",
       " -107.27820587158203,\n",
       " -122.93270874023438,\n",
       " -134.7869873046875,\n",
       " -65.36846160888672,\n",
       " -109.67047119140625,\n",
       " 101.00432586669922,\n",
       " -53.79298782348633,\n",
       " -103.96897888183594,\n",
       " -157.08221435546875,\n",
       " -95.06204223632812,\n",
       " -71.18231964111328,\n",
       " -123.42967224121094,\n",
       " -116.34916687011719,\n",
       " -104.89444732666016,\n",
       " -92.24810028076172,\n",
       " -126.440185546875,\n",
       " -123.58448791503906,\n",
       " -133.2726593017578,\n",
       " -141.5427703857422,\n",
       " -87.13719177246094,\n",
       " -109.0503158569336,\n",
       " -123.66313934326172,\n",
       " -119.4629898071289,\n",
       " -120.83660125732422,\n",
       " -124.58316040039062,\n",
       " -136.22125244140625,\n",
       " 9.093180656433105,\n",
       " -145.34762573242188,\n",
       " -112.01044464111328,\n",
       " -169.12234497070312,\n",
       " -142.4510498046875,\n",
       " -103.28901672363281,\n",
       " -100.46314239501953,\n",
       " -100.839599609375,\n",
       " -115.33179473876953,\n",
       " -103.99850463867188,\n",
       " -103.0804443359375,\n",
       " -48.55424880981445,\n",
       " -90.03695678710938,\n",
       " -101.6174545288086,\n",
       " -78.02801513671875,\n",
       " -103.12394714355469,\n",
       " -88.88520812988281,\n",
       " -113.82698059082031,\n",
       " -114.05917358398438,\n",
       " -103.30703735351562,\n",
       " -94.50685119628906,\n",
       " -123.39549255371094,\n",
       " -138.35353088378906,\n",
       " -112.38217163085938,\n",
       " -117.84484100341797,\n",
       " -114.69200897216797,\n",
       " -111.35892486572266,\n",
       " -50.354000091552734,\n",
       " -116.06363677978516,\n",
       " -106.09114074707031,\n",
       " -92.95760345458984,\n",
       " -94.55316162109375,\n",
       " -127.69855499267578,\n",
       " -115.31719207763672,\n",
       " -81.7200927734375,\n",
       " -96.31877136230469,\n",
       " -102.71944427490234,\n",
       " -163.1831817626953,\n",
       " -148.3914794921875,\n",
       " -145.29515075683594,\n",
       " -116.75370025634766,\n",
       " -69.09532165527344,\n",
       " -109.41153717041016,\n",
       " -96.03636169433594,\n",
       " -98.82286834716797,\n",
       " -90.19490051269531,\n",
       " -101.66036224365234,\n",
       " -95.24347686767578,\n",
       " -95.65306854248047,\n",
       " -90.62140655517578,\n",
       " -110.1413803100586,\n",
       " -57.87794494628906,\n",
       " -107.42092895507812,\n",
       " -138.89210510253906,\n",
       " -130.3790740966797,\n",
       " -115.31340026855469,\n",
       " -107.21639251708984,\n",
       " -127.3078384399414,\n",
       " -108.16284942626953,\n",
       " -101.53118133544922,\n",
       " -112.79151153564453,\n",
       " -107.50224304199219,\n",
       " -166.95401000976562,\n",
       " -144.65628051757812,\n",
       " -133.81964111328125,\n",
       " -78.7866439819336,\n",
       " -114.0760269165039,\n",
       " -125.93123626708984,\n",
       " -125.02694702148438,\n",
       " -118.89376068115234,\n",
       " -137.8300018310547,\n",
       " -132.44381713867188,\n",
       " -107.67660522460938,\n",
       " -117.90400695800781,\n",
       " -116.95254516601562,\n",
       " -104.02577209472656,\n",
       " -115.53839874267578,\n",
       " -107.010498046875,\n",
       " -123.34555053710938,\n",
       " -163.04830932617188,\n",
       " -116.70806121826172,\n",
       " -99.735107421875,\n",
       " -70.33966064453125,\n",
       " -106.60433197021484,\n",
       " -112.89256286621094,\n",
       " -109.40584564208984,\n",
       " -128.14935302734375,\n",
       " -126.98966979980469,\n",
       " -120.95306396484375,\n",
       " -126.53807830810547,\n",
       " -142.9623260498047,\n",
       " -104.72145080566406,\n",
       " -111.10607147216797,\n",
       " -124.12115478515625,\n",
       " -107.8946762084961,\n",
       " -138.03976440429688,\n",
       " -92.58485412597656,\n",
       " -118.64767456054688,\n",
       " -113.5915298461914,\n",
       " -120.49156951904297,\n",
       " -121.73302459716797,\n",
       " -80.23273468017578,\n",
       " -85.98080444335938,\n",
       " -100.75308227539062,\n",
       " -111.45374298095703,\n",
       " -124.03058624267578,\n",
       " -46.10248947143555,\n",
       " -108.88451385498047,\n",
       " -167.36453247070312,\n",
       " -152.07749938964844,\n",
       " -76.1629638671875,\n",
       " -73.88426208496094,\n",
       " -99.05501556396484,\n",
       " -56.312557220458984,\n",
       " -78.26073455810547,\n",
       " -109.1788101196289,\n",
       " -99.29473876953125,\n",
       " -96.01349639892578,\n",
       " -139.55682373046875,\n",
       " -133.7147979736328,\n",
       " -119.35523223876953,\n",
       " -122.98062133789062,\n",
       " -99.12763214111328,\n",
       " -112.1748046875,\n",
       " -120.65013122558594,\n",
       " -130.66539001464844,\n",
       " -117.1290054321289,\n",
       " -124.95899963378906,\n",
       " -144.74720764160156,\n",
       " -109.2672119140625,\n",
       " -103.06241607666016,\n",
       " -108.21147918701172,\n",
       " -110.53814697265625,\n",
       " -104.54474639892578,\n",
       " -122.31517028808594,\n",
       " -110.13204193115234,\n",
       " -164.675537109375,\n",
       " -140.5330047607422,\n",
       " -138.74827575683594,\n",
       " -48.840065002441406,\n",
       " -126.05035400390625,\n",
       " -112.8668441772461,\n",
       " -110.50889587402344,\n",
       " -134.26522827148438,\n",
       " -81.815185546875,\n",
       " -88.11280822753906,\n",
       " -56.34172821044922,\n",
       " -104.5008773803711,\n",
       " -127.23277282714844,\n",
       " -124.16158294677734,\n",
       " -116.33871459960938,\n",
       " -95.3691177368164,\n",
       " -102.94534301757812,\n",
       " -108.19429779052734,\n",
       " -91.37185668945312,\n",
       " -107.50328063964844,\n",
       " -101.71647644042969,\n",
       " -105.1968002319336,\n",
       " -128.040283203125,\n",
       " -81.9624252319336,\n",
       " -106.23692321777344,\n",
       " -120.75062561035156,\n",
       " -100.13232421875,\n",
       " -95.97233581542969,\n",
       " -149.05665588378906,\n",
       " -161.78707885742188,\n",
       " -145.61436462402344,\n",
       " -137.50888061523438,\n",
       " -126.26824188232422,\n",
       " -109.44970703125,\n",
       " -107.72377014160156,\n",
       " -141.55313110351562,\n",
       " -137.3215789794922,\n",
       " -161.95663452148438,\n",
       " -110.58967590332031,\n",
       " -83.24500274658203,\n",
       " -125.5587387084961,\n",
       " -134.96510314941406,\n",
       " -130.92135620117188,\n",
       " -124.81147766113281,\n",
       " -135.43431091308594,\n",
       " -103.89493560791016,\n",
       " -95.72582244873047,\n",
       " -102.6553955078125,\n",
       " -124.72704315185547,\n",
       " -112.16182708740234,\n",
       " -110.3926773071289,\n",
       " -104.50898742675781,\n",
       " -154.33853149414062,\n",
       " -120.75035858154297,\n",
       " -110.86229705810547,\n",
       " -42.014495849609375,\n",
       " -85.86876678466797,\n",
       " -122.25312042236328,\n",
       " -113.14773559570312,\n",
       " -111.50457000732422,\n",
       " -133.2099609375,\n",
       " -108.92285919189453,\n",
       " -63.61729431152344,\n",
       " -98.82292175292969,\n",
       " -130.72305297851562,\n",
       " -136.33169555664062,\n",
       " -136.50588989257812,\n",
       " -134.7671661376953,\n",
       " -109.5060806274414,\n",
       " -130.19993591308594,\n",
       " -136.13014221191406,\n",
       " -73.45616149902344,\n",
       " -111.23545837402344,\n",
       " -114.768310546875,\n",
       " -110.43307495117188,\n",
       " -64.8769302368164,\n",
       " -100.66366577148438,\n",
       " -104.26673889160156,\n",
       " -139.1084747314453,\n",
       " -86.04452514648438,\n",
       " -114.69252014160156,\n",
       " -142.5598602294922,\n",
       " -137.6823272705078,\n",
       " -74.95013427734375,\n",
       " -120.92155456542969,\n",
       " -143.53244018554688,\n",
       " -114.78243255615234,\n",
       " -130.71603393554688,\n",
       " -118.2053451538086,\n",
       " -128.5533447265625,\n",
       " -119.14826202392578,\n",
       " -138.85813903808594,\n",
       " -147.02236938476562,\n",
       " -131.52841186523438,\n",
       " -74.74317932128906,\n",
       " -50.960716247558594,\n",
       " -95.07215881347656,\n",
       " -85.10226440429688,\n",
       " -88.77794647216797,\n",
       " -95.7801513671875,\n",
       " -112.41703796386719,\n",
       " -126.31818389892578,\n",
       " -73.39879608154297,\n",
       " -98.80541229248047,\n",
       " -119.52255249023438,\n",
       " -74.93397521972656,\n",
       " -157.3649444580078,\n",
       " -112.11924743652344,\n",
       " -124.75238037109375,\n",
       " -135.87681579589844,\n",
       " -80.39892578125,\n",
       " -87.18280029296875,\n",
       " -101.47799682617188,\n",
       " -108.91259002685547,\n",
       " -144.7048797607422,\n",
       " -38.136295318603516,\n",
       " -109.52193450927734,\n",
       " -128.5029296875,\n",
       " -130.23065185546875,\n",
       " -114.99938201904297,\n",
       " -118.41377258300781,\n",
       " -91.42855072021484,\n",
       " -84.52690124511719,\n",
       " -77.55388641357422,\n",
       " -111.98287200927734,\n",
       " -116.40650177001953,\n",
       " -109.93009948730469,\n",
       " -134.90187072753906,\n",
       " -97.56975555419922,\n",
       " -46.450809478759766,\n",
       " -80.2396469116211,\n",
       " -128.11056518554688,\n",
       " -71.1137924194336,\n",
       " -115.48680877685547,\n",
       " -78.68399047851562,\n",
       " -119.33253479003906,\n",
       " -6.75644588470459,\n",
       " -99.93757629394531,\n",
       " -107.7596206665039,\n",
       " -50.673583984375,\n",
       " -119.97771453857422,\n",
       " -120.15190887451172,\n",
       " -105.23004150390625,\n",
       " -82.01848602294922,\n",
       " -105.25782012939453,\n",
       " -111.68415832519531,\n",
       " -85.83673095703125,\n",
       " -124.69449615478516,\n",
       " -117.17514038085938,\n",
       " -119.8551025390625,\n",
       " -122.56266021728516,\n",
       " -109.74720764160156,\n",
       " -129.18544006347656,\n",
       " -91.09844970703125,\n",
       " -63.55354690551758,\n",
       " -116.61766815185547,\n",
       " -152.0653839111328,\n",
       " -118.20603942871094,\n",
       " -126.66136932373047,\n",
       " -91.80341339111328,\n",
       " -99.8109130859375,\n",
       " -124.17230987548828,\n",
       " -101.181884765625,\n",
       " -116.95308685302734,\n",
       " -115.80980682373047,\n",
       " -117.53497314453125,\n",
       " -98.49462890625,\n",
       " -130.69776916503906,\n",
       " -118.5534439086914,\n",
       " -90.74022674560547,\n",
       " -163.69525146484375,\n",
       " -142.1436309814453,\n",
       " -149.19921875,\n",
       " -101.60337829589844,\n",
       " -129.45343017578125,\n",
       " -108.39900207519531,\n",
       " -77.07756042480469,\n",
       " -109.86198425292969,\n",
       " -110.91700744628906,\n",
       " -112.15690612792969,\n",
       " -117.9690933227539,\n",
       " -123.22610473632812,\n",
       " -127.15270233154297,\n",
       " -134.23239135742188,\n",
       " -97.56178283691406,\n",
       " -117.64718627929688,\n",
       " -130.0601043701172,\n",
       " -155.16676330566406,\n",
       " -141.040283203125,\n",
       " -152.18251037597656,\n",
       " -120.21150207519531,\n",
       " -125.22383880615234,\n",
       " -119.1346435546875,\n",
       " -106.39136505126953,\n",
       " -112.31047821044922,\n",
       " -112.68617248535156,\n",
       " -164.49008178710938,\n",
       " -115.2263412475586,\n",
       " -140.1077423095703,\n",
       " -132.9150848388672,\n",
       " -91.06318664550781,\n",
       " -108.68026733398438,\n",
       " -111.22050476074219,\n",
       " -94.0311050415039,\n",
       " -100.74271392822266,\n",
       " -109.17927551269531,\n",
       " -113.42613220214844,\n",
       " -91.39862823486328,\n",
       " -87.59609985351562,\n",
       " -158.18197631835938,\n",
       " -143.4837646484375,\n",
       " -153.19374084472656,\n",
       " -138.37400817871094,\n",
       " -131.8078155517578,\n",
       " -110.42365264892578,\n",
       " -135.47280883789062,\n",
       " -135.7091064453125,\n",
       " -140.39013671875,\n",
       " -153.70281982421875,\n",
       " -128.29222106933594,\n",
       " -158.4515380859375,\n",
       " -136.36790466308594,\n",
       " -122.93590545654297,\n",
       " -120.68863677978516,\n",
       " -120.99129486083984,\n",
       " -116.37812805175781,\n",
       " -99.42882537841797,\n",
       " -148.0487518310547,\n",
       " -135.1778106689453,\n",
       " -157.25831604003906,\n",
       " -145.3831024169922,\n",
       " -121.00526428222656,\n",
       " -129.35865783691406,\n",
       " -135.51425170898438,\n",
       " -114.06136322021484,\n",
       " -103.69561004638672,\n",
       " -92.20361328125,\n",
       " -115.12742614746094,\n",
       " -120.02423095703125,\n",
       " -124.63504791259766,\n",
       " -107.40853118896484,\n",
       " -13.726627349853516,\n",
       " -150.21205139160156,\n",
       " -122.23895263671875,\n",
       " -142.79603576660156,\n",
       " -158.23204040527344,\n",
       " -139.8096923828125,\n",
       " -111.20563507080078,\n",
       " -125.49390411376953,\n",
       " -104.34935760498047,\n",
       " -93.99119567871094,\n",
       " -159.3924102783203,\n",
       " -106.48008728027344,\n",
       " -120.15097045898438,\n",
       " -114.09320068359375,\n",
       " -134.29762268066406,\n",
       " -127.8095474243164,\n",
       " -104.11741638183594,\n",
       " -116.1998519897461,\n",
       " -111.00093078613281,\n",
       " -118.8510513305664,\n",
       " -112.09619903564453,\n",
       " -113.26079559326172,\n",
       " -135.3284454345703,\n",
       " -137.97166442871094,\n",
       " -111.21437072753906,\n",
       " -130.274658203125,\n",
       " -136.3685760498047,\n",
       " -99.2991943359375,\n",
       " -152.97679138183594,\n",
       " -102.22988891601562,\n",
       " -148.31573486328125,\n",
       " -96.23355102539062,\n",
       " -114.61470031738281,\n",
       " -76.7695541381836,\n",
       " -120.06361389160156,\n",
       " -154.76101684570312,\n",
       " -110.43943786621094,\n",
       " -82.38481140136719,\n",
       " -111.2823257446289,\n",
       " -121.86285400390625,\n",
       " -126.05238342285156,\n",
       " -106.96469116210938,\n",
       " -106.84701538085938,\n",
       " -110.97196197509766,\n",
       " -79.20201873779297,\n",
       " -83.11638641357422,\n",
       " -118.45419311523438,\n",
       " -92.95292663574219,\n",
       " -89.99038696289062,\n",
       " -47.84899139404297,\n",
       " -128.3860626220703,\n",
       " -124.69857788085938,\n",
       " -109.18840026855469,\n",
       " -80.8852310180664,\n",
       " -113.37647247314453,\n",
       " -102.00501251220703,\n",
       " -112.78417205810547,\n",
       " -141.7671661376953,\n",
       " -92.0885238647461,\n",
       " -93.5400619506836,\n",
       " -103.89686584472656,\n",
       " -113.82804870605469,\n",
       " -152.49766540527344,\n",
       " -90.41781616210938,\n",
       " -133.37965393066406,\n",
       " -123.16191864013672,\n",
       " -91.4265365600586,\n",
       " -101.5722885131836,\n",
       " -105.53717041015625,\n",
       " -112.118896484375,\n",
       " -147.08041381835938,\n",
       " -120.70281219482422,\n",
       " -103.74846649169922,\n",
       " -132.15638732910156,\n",
       " -128.3644256591797,\n",
       " -131.7312774658203,\n",
       " -119.05966186523438,\n",
       " -116.09931945800781,\n",
       " -128.80029296875,\n",
       " -85.42382049560547,\n",
       " -153.0585174560547,\n",
       " -25.912254333496094,\n",
       " -93.07000732421875,\n",
       " -116.37403869628906,\n",
       " -117.63845825195312,\n",
       " -117.43994903564453,\n",
       " -117.74221801757812,\n",
       " -103.86913299560547,\n",
       " -68.78439331054688,\n",
       " -98.97510528564453,\n",
       " -105.02851104736328,\n",
       " -156.80308532714844,\n",
       " -139.37840270996094,\n",
       " -100.44136047363281,\n",
       " -109.0528335571289,\n",
       " -109.68826293945312,\n",
       " -98.45929718017578,\n",
       " -101.19293212890625,\n",
       " -124.67134857177734,\n",
       " -140.5414276123047,\n",
       " -147.4031219482422,\n",
       " -131.53616333007812,\n",
       " -125.25234985351562,\n",
       " -143.30126953125,\n",
       " -126.88143157958984,\n",
       " -93.14380645751953,\n",
       " -141.96490478515625,\n",
       " -108.88566589355469,\n",
       " -143.0950469970703,\n",
       " -139.88758850097656,\n",
       " -91.27903747558594,\n",
       " -136.87234497070312,\n",
       " -108.91927337646484,\n",
       " -87.04611206054688,\n",
       " -109.87281799316406,\n",
       " -85.83064270019531,\n",
       " -53.73741912841797,\n",
       " -112.25827026367188,\n",
       " -101.98033905029297,\n",
       " -133.13792419433594,\n",
       " -131.9100799560547,\n",
       " -85.06302642822266,\n",
       " -111.45559692382812,\n",
       " -114.70002746582031,\n",
       " -141.0487060546875,\n",
       " -113.80142211914062,\n",
       " -92.32395935058594,\n",
       " -118.61968994140625,\n",
       " -114.56251525878906,\n",
       " -100.26083374023438,\n",
       " -96.83026123046875,\n",
       " -98.62073516845703,\n",
       " -55.04393005371094,\n",
       " -124.36071014404297,\n",
       " -62.147220611572266,\n",
       " -77.0236587524414,\n",
       " -110.85726928710938,\n",
       " -98.59661865234375,\n",
       " -138.876953125,\n",
       " -122.54178619384766,\n",
       " -103.14556884765625,\n",
       " -86.50791931152344,\n",
       " -99.8268814086914,\n",
       " -48.4703254699707,\n",
       " -71.63926696777344,\n",
       " -142.2701873779297,\n",
       " -73.29090881347656,\n",
       " -116.48125457763672,\n",
       " -134.47059631347656,\n",
       " -158.71304321289062,\n",
       " -125.86048126220703,\n",
       " -98.05553436279297,\n",
       " -113.75643920898438,\n",
       " -108.11064147949219,\n",
       " -85.7494125366211,\n",
       " -81.42984771728516,\n",
       " -77.93108367919922,\n",
       " -101.26263427734375,\n",
       " -86.14265441894531,\n",
       " -74.89299011230469,\n",
       " -98.31044006347656,\n",
       " -76.9783706665039,\n",
       " -148.6878662109375,\n",
       " -143.6066131591797,\n",
       " -129.89602661132812,\n",
       " -91.1943359375,\n",
       " -110.69690704345703,\n",
       " -127.5980224609375,\n",
       " -110.5810546875,\n",
       " -117.25952911376953,\n",
       " -101.70333862304688,\n",
       " -111.64061737060547,\n",
       " -99.3912582397461,\n",
       " -106.18363189697266,\n",
       " -158.97705078125,\n",
       " -128.17068481445312,\n",
       " -82.39273071289062,\n",
       " -63.498779296875,\n",
       " -85.79466247558594,\n",
       " -101.3467025756836,\n",
       " -92.96504211425781,\n",
       " -115.40198516845703,\n",
       " -94.98291015625,\n",
       " -173.59024047851562,\n",
       " -129.08352661132812,\n",
       " -98.96157836914062,\n",
       " -80.80851745605469,\n",
       " -75.66006469726562,\n",
       " -87.2650375366211,\n",
       " -117.68571472167969,\n",
       " -116.25713348388672,\n",
       " -106.35067749023438,\n",
       " -88.72240447998047,\n",
       " -123.17218017578125,\n",
       " -130.12489318847656,\n",
       " -138.27206420898438,\n",
       " -124.3064193725586,\n",
       " -123.67774200439453,\n",
       " -173.08331298828125,\n",
       " -91.84174346923828,\n",
       " -155.17752075195312,\n",
       " -101.3975601196289,\n",
       " 11.742439270019531,\n",
       " -98.17559814453125,\n",
       " -111.08443450927734,\n",
       " -105.05520629882812,\n",
       " -86.9312973022461,\n",
       " -106.52818298339844,\n",
       " -102.48340606689453,\n",
       " -124.91068267822266,\n",
       " -84.1695556640625,\n",
       " -116.74849700927734,\n",
       " -177.00059509277344,\n",
       " -110.16161346435547,\n",
       " -108.71846008300781,\n",
       " -137.00001525878906,\n",
       " -141.1060791015625,\n",
       " -122.49664306640625,\n",
       " -124.64984893798828,\n",
       " -132.8305206298828,\n",
       " -111.1941146850586,\n",
       " 113.2570571899414,\n",
       " -95.33906555175781,\n",
       " -126.52857208251953,\n",
       " -112.7461929321289,\n",
       " -128.1151123046875,\n",
       " -127.7320327758789,\n",
       " -124.65738677978516,\n",
       " -171.82797241210938,\n",
       " -147.2996063232422,\n",
       " -138.32479858398438,\n",
       " -98.48304748535156,\n",
       " -97.78264617919922,\n",
       " -129.22837829589844,\n",
       " -103.22733306884766,\n",
       " -108.93415832519531,\n",
       " -107.23466491699219,\n",
       " -83.4825439453125,\n",
       " -93.15657043457031,\n",
       " -110.3436050415039,\n",
       " -77.04478454589844,\n",
       " -116.20687866210938,\n",
       " -166.57432556152344,\n",
       " -110.514404296875,\n",
       " -124.88194274902344,\n",
       " 85.65885925292969,\n",
       " -77.14315032958984,\n",
       " -102.3848648071289,\n",
       " -96.91795349121094,\n",
       " -64.90465545654297,\n",
       " -102.5677719116211,\n",
       " -101.82832336425781,\n",
       " -168.3137969970703,\n",
       " -109.46849822998047,\n",
       " -117.2340087890625,\n",
       " -126.47390747070312,\n",
       " -124.22454833984375,\n",
       " -110.98645782470703,\n",
       " -125.34358215332031,\n",
       " -115.55613708496094,\n",
       " -135.34127807617188,\n",
       " -91.38090515136719,\n",
       " -122.06562042236328,\n",
       " -107.3504409790039,\n",
       " -116.39622497558594,\n",
       " -129.58062744140625,\n",
       " -114.97183990478516,\n",
       " -124.33802032470703,\n",
       " -92.06058502197266,\n",
       " -115.77851867675781,\n",
       " -159.11537170410156,\n",
       " -123.27338409423828,\n",
       " -123.43878936767578,\n",
       " -57.736873626708984,\n",
       " -125.41158294677734,\n",
       " -94.77387237548828,\n",
       " -102.67472076416016,\n",
       " -138.04505920410156,\n",
       " -144.48182678222656,\n",
       " -108.77383422851562,\n",
       " -107.14546966552734,\n",
       " -123.4010009765625,\n",
       " -96.75542449951172,\n",
       " -125.36369323730469,\n",
       " -159.26571655273438,\n",
       " -112.95480346679688,\n",
       " -146.7920379638672,\n",
       " -124.31515502929688,\n",
       " -86.96231842041016,\n",
       " -122.24642944335938,\n",
       " -118.47329711914062,\n",
       " -95.26760864257812,\n",
       " -96.22317504882812,\n",
       " -126.52127075195312,\n",
       " -11.807616233825684,\n",
       " -91.53813171386719,\n",
       " -113.59039306640625,\n",
       " -162.7275390625,\n",
       " -159.79010009765625,\n",
       " -136.3452606201172,\n",
       " -68.30412292480469,\n",
       " -131.26536560058594,\n",
       " -146.9733123779297,\n",
       " -97.35450744628906,\n",
       " -114.09285736083984,\n",
       " -159.96131896972656,\n",
       " -94.59752655029297,\n",
       " -163.34764099121094,\n",
       " -129.41334533691406,\n",
       " -98.37623596191406,\n",
       " -100.13483428955078,\n",
       " -160.94342041015625,\n",
       " -141.9210968017578,\n",
       " -134.0309600830078,\n",
       " -145.27210998535156,\n",
       " -166.0722198486328,\n",
       " -115.17688751220703,\n",
       " -115.82140350341797,\n",
       " -116.75557708740234,\n",
       " -125.36470031738281,\n",
       " -114.4300308227539,\n",
       " -117.84223175048828,\n",
       " -98.27179718017578,\n",
       " -133.03746032714844,\n",
       " -133.79202270507812,\n",
       " -109.6941909790039,\n",
       " -152.84278869628906,\n",
       " -126.23603820800781,\n",
       " -62.561126708984375,\n",
       " -130.62802124023438,\n",
       " -91.52225494384766,\n",
       " -150.25399780273438,\n",
       " -105.09652709960938,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_list[iWord] in string.punctuation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
